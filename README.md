# PICO - Performance Insights for Collective Operations

**PICO** is a **lightweight**, **extensible**, and **reproducible** benchmarking suite for evaluating and tuning **collective communication operations** across diverse libraries and hardware platforms.

Built for researchers, developers, and system administrators, PICO streamlines the **entire benchmarking workflow**â€”from configuration to execution, tracing, and analysisâ€”across MPI, NCCL, and user-defined collectives.

---

## ðŸ” Why PICO?

Benchmarking collectives at scale is hard. Libraries vary, hardware stacks are complex, and existing tools often provide only coarse metrics with little automation.

**PICO addresses this by providing:**

- ðŸ“¦ **Unified testing** across MPI (OMPI, MPICH, CrayMPICH), NCCL, and custom implementations.
- ðŸŽ›ï¸ **Configuration via CLI or TUI**, with reproducible, declarative test descriptions.
- ðŸ“Š **Built-in analysis tools** and plotting scripts to extract insights quickly.
- ðŸ“‹ **Automatic metadata collection**: environment variables, library/runtime versions, hardware info.
- ðŸ”¬ **Fine-grained instrumentation** for analyzing internal phases of collective operations.

---

## ðŸ’¡ Key Features

- **Multi-library support**:
  - âœ… MPI (OMPI, MPICH, Cray MPICH)
  - âœ… NCCL (NVIDIA)
- **Extensibility**:
  - Plug in new collectives or libraries with minimal glue code.
- **Reproducibility**:
  - Complete environment capture (UCX, OFI, SHARP, etc.)
  - JSON-based configuration and results logging.
- **Integrated visualization**:
  - CSV output, tracer utilities, and publication-ready plots.
- **Active TUI development**:
  - CLI-based now, full interactive UI under construction.


## ðŸš€ Quickstart

To explore available benchmarking options or start a test, run:

```bash
scripts/submit_wrapper.sh --help
````

This command-line tool will guide you through job setup and execution.

> A full-featured **Terminal UI (TUI)** for interactive config generation is in active development.

---

## ðŸ“ Project Structure

```
PICO/
â”œâ”€â”€ config/        # Benchmark configuration files and templates
â”œâ”€â”€ include/       # Header files
â”œâ”€â”€ libbine/       # Benchmark infrastructure core
â”œâ”€â”€ pico_core/     # Main orchestration and benchmarking engine
â”œâ”€â”€ plot/          # Scripts for result visualization
â”œâ”€â”€ results/       # Collected output and logs
â”œâ”€â”€ scripts/       # Submission and utility scripts (e.g., submit_wrapper.sh)
â”œâ”€â”€ selector/      # Backend/algorithm selection logic
â”œâ”€â”€ tracer/        # Tracing utilities for network traffic analysis
â”œâ”€â”€ tui/           # Terminal UI for guided test creation (in progress)
â”œâ”€â”€ LICENSE        # License information
â”œâ”€â”€ Makefile       # Build system
â””â”€â”€ README.md      # This file
```

---

## ðŸ“Š Analysis and Tracing

* **CSV result summaries** and formatted terminal logs
* **Tracer utility** to visualize traffic across global links
* **Integrated plotting scripts** for high-quality publication-ready figures
* **Instrumentation hooks** for per-stage timing and bandwidth analysis

---

## ðŸ“Œ Supported Platforms

* Validated on:

  * ðŸ‡ªðŸ‡º **Leonardo**
  * ðŸ‡ªðŸ‡º **LUMI**
  * ðŸ‡ªðŸ‡º **MareNostrum 5**

Compatible with **SLURM-based** job schedulers. Other environments can be added via JSON-based platform descriptors.

---

## ðŸ§© Development Roadmap

* âœ… Stable benchmarking and metadata capture
* âœ… NCCL + MPI support
* âœ… CLI-based submission
* ðŸ”œ Full-featured TUI for test config generation
* ðŸ”œ Simplified platform setup and expansion


## ðŸ¤ Acknowledgments

PICO is developed by Daniele De Sensi ans Saverio Pasqualoni
Department of Computer Science, Sapienza University of Rome

> For questions or contributions, please contact:
> [desensi@di.uniroma1.it](mailto:desensi@di.uniroma1.it)
> [pasqualoni.1845572@studenti.uniroma1.it](mailto:pasqualoni.1845572@studenti.uniroma1.it)

